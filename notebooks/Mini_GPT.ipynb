{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp313-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Using cached torch-2.7.1-cp313-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, setuptools, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [torch]m 9/10\u001b[0m [torch]]x]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 setuptools-80.9.0 sympy-1.14.0 torch-2.7.1 typing-extensions-4.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushyapare/Ayushyas_Life/Work/Research/DeGrueter_TM_2025/IDAM/.venv_idam/lib/python3.13/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      avg_loss  runtime_sec\n",
      "SGD   1.290987     0.633550\n",
      "Adam  5.409834     0.733557\n",
      "IDAM  1.342105     0.703720\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import random\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Device setup for Apple M2\n",
    "# ---------------------------------------------\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Tiny Dataset (synthetic text data)\n",
    "# ---------------------------------------------\n",
    "vocab_size = 100\n",
    "seq_length = 128\n",
    "batch_size = 8\n",
    "num_batches = 50\n",
    "\n",
    "def generate_fake_data():\n",
    "    return torch.randint(0, vocab_size, (batch_size, seq_length), dtype=torch.long)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Tiny Transformer-style LLM (MiniGPT)\n",
    "# ---------------------------------------------\n",
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, n_heads=4, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=n_heads)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.fc_out = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.token_embedding(x)  # (B, T, C)\n",
    "        x = x.permute(1, 0, 2)       # Transformer expects (T, B, C)\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        return self.fc_out(x)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Custom IDAM Optimizer\n",
    "# ---------------------------------------------\n",
    "class IDAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, alpha=1e-2, eps=1e-8):\n",
    "        defaults = dict(alpha=alpha, eps=eps)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        for group in self.param_groups:\n",
    "            alpha = group['alpha']\n",
    "            eps = group['eps']\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                state = self.state[p]\n",
    "                if 'prev_param' not in state:\n",
    "                    state['prev_param'] = p.data.clone()\n",
    "                displacement = p.data - state['prev_param']\n",
    "                eta = alpha / (torch.sqrt(1 + displacement**2) + eps)\n",
    "                state['prev_param'] = p.data.clone()\n",
    "                p.data -= eta * p.grad\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Training Function\n",
    "# ---------------------------------------------\n",
    "def train_model(optimizer_name):\n",
    "    model = MiniGPT(vocab_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if optimizer_name == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "    elif optimizer_name == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    elif optimizer_name == \"IDAM\":\n",
    "        optimizer = IDAM(model.parameters(), alpha=0.1)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer\")\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        x = generate_fake_data().to(device)\n",
    "        y = x.clone().to(device)  # next-token prediction\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output.view(-1, vocab_size), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    end_time = time.time()\n",
    "    avg_loss = total_loss / num_batches\n",
    "    runtime = end_time - start_time\n",
    "    return avg_loss, runtime\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Run Training with All Optimizers\n",
    "# ---------------------------------------------\n",
    "results = {}\n",
    "for opt_name in [\"SGD\", \"Adam\", \"IDAM\"]:\n",
    "    loss, runtime = train_model(opt_name)\n",
    "    results[opt_name] = {\"avg_loss\": loss, \"runtime_sec\": runtime}\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Print Results\n",
    "# ---------------------------------------------\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results).T\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_idam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
